{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "CURR_DIR = os.path.dirname('__file__')\n",
    "ROOT_DIR=os.path.join(os.getcwd() ,'..')\n",
    "sys.path.append(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "#load configs\n",
    "config = OmegaConf.load(os.path.join(ROOT_DIR,'run_scripts/configs/config.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'model': {'target': 'models.classifier.Classifier', 'params': {'data_dir': '/home/akshay/Documents/cse_sem_7/conxai_assignment/cloned/stage-classification/data', 'image_size': 150, 'channels': 3, 'num_classes': 7, 'batch_size': 16, 'max_tsteps': 10, 'learning_rate': 0.001, 'loss_type': 'cross_entropy', 'nn_model': {'target': 'models.cnn.CNNClassification', 'params': {'input_channels': 3, 'num_classes': 7}}}}}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 14:40:10.866854: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-01-22 14:40:10.866879: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from utilities.initialize_configs import instantiate_from_configs\n",
    "classifierModel = instantiate_from_configs(config.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# ddpmModel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for batch in classifierModel.train_dataloader():\n",
    "    print(batch[1].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | CNNClassification | 86.6 M\n",
      "--------------------------------------------\n",
      "86.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "86.6 M    Total params\n",
      "346.361   Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar, Timer, ModelCheckpoint\n",
    "import time\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# stop training after 12 hours\n",
    "timer = Timer(duration=\"00:12:00:00\")\n",
    "\n",
    "# or provide a datetime.timedelta\n",
    "from datetime import timedelta\n",
    "timer = Timer(duration=timedelta(weeks=1))\n",
    "timestr = time.strftime(\"%d%m%y-%H%M%S\")\n",
    "loss_type = classifierModel.loss_type\n",
    "alpha = classifierModel.learning_rate\n",
    "task = 'cnn-classification'\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "#     dirpath=CKPT_DIR,\n",
    "    save_top_k=2,\n",
    "    monitor=\"val/loss_simple\",    \n",
    "    filename=timestr + \"-{epoch}-{step}-\" + \"-loss=%s\"%loss_type + \"-a=%.1E\"%alpha\n",
    ")\n",
    "# trainer = Trainer(max_steps=ddpmModel.max_tsteps, accelerator=\"gpu\", devices=-1, logger=wandb_logger, callbacks=[TQDMProgressBar(refresh_rate=10), timer, checkpoint]) # To use all available GPUs put -1 or '-1'\n",
    "trainer = Trainer(max_steps=classifierModel.max_tsteps, callbacks=[TQDMProgressBar(refresh_rate=10), timer, checkpoint]) # To use all available GPUs put -1 or '-1'\n",
    "trainer.fit(classifierModel)\n",
    "\n",
    "# query training/validation/test time (in seconds)\n",
    "print(\"Total training time: %.2f mins\" % (timer.time_elapsed(\"train\")/60))\n",
    "\n",
    "# save last checkpoint\n",
    "timestr = time.strftime(\"%d%m%y-%H%M%S\")\n",
    "train_loss = \"{:.4f}\".format(trainer.logged_metrics['train/loss'].item())\n",
    "CKPT_NAME = timestr + \"_lastckpt_tloss_\" + str(train_loss) + \".ckpt\"\n",
    "logger_version = \"version_\"+str(trainer.logger.version)\n",
    "PATH = \"lightning_logs/\" + logger_version+ \"/checkpoints/\"+CKPT_NAME\n",
    "trainer.save_checkpoint(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fleetsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
